# 神经网络作为通用逼近器
**sigmoid**
通过神经网络可以模拟任意的布尔运算与多项式运算。

神经网络模拟情况的好坏取决于网络的深度和宽度。如果只用一层的话需要的节点数将会呈指数级增长，因此我们会用多层网络来进行模拟。

同时在网络的训练过程中在每一层的传递时需要考虑信息的损失，sigmoid激活函数会损失两端的信息，造成失真现象，常用于最后一层不需要回传信息时。其余层多用ReLU函数进行激活保留各层信息。
# 训练神经网络
#### 感知机
感知机--找到一个线性超平面区分正负样本

线性平面能够分开所有样本，并使所以样本距其最远。权重W是这个 超平面的法线，它会尽可能的指向正样本背离负样本，经过反复迭代找出最适位置。偏置b是为了找到所有样本中间位置。

只有前向传播寻找复杂样本的分界线将会是一个NP问题。所以为了解决问题引入了反向传播，同时为了使反向传播可导使用sigmoid做激活函数，又因为多数样本存在与x的中间位置，sigmoid对两边数据的区分度高，对中间位置区分度较低，所以给予出现次数多的样本更高的权重，出现次数少的样本较低权重。相当于求函数的概率期望。